---
---

@inproceedings{huang2019mvscn,
	Address = {Macao, China},
	Author = {Huang, Zhenyu and Zhou, Joey Tianyi and Peng, Xi and Zhang, Changqing and Zhu, Hongyuan and Lv, Jiancheng},
	Booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},  
	Month = {10--16 Aug},
	Pages = {2563--2569},
	Title = {Multi-view Spectral Clustering Network},
	Url = {https://doi.org/10.24963/ijcai.2019/356},
	Volume = {},
	Year = {2019},
	html = {https://doi.org/10.24963/ijcai.2019/356},
	doi = {10.24963/ijcai.2019/356},
	bib = {huang2019mvscn.bib},
	Pdfurl = {https://www.ijcai.org/proceedings/2019/0356.pdf},
	code = {https://github.com/hi-zhenyu/MvSCN},
	Abstract = {Multi-view clustering aims to cluster data from diverse sources or domains, which has drawn considerable attention in recent years. In this paper, we propose a novel multi-view clustering method named multi-view spectral clustering network (MvSCN) which could be the first deep version of multi-view spectral clustering to the best of our knowledge. To deeply cluster multi-view data, MvSCN incorporates the local invariance within every single view and the consistency across different views into a novel objective function, where the local invariance is defined by a deep metric learning network rather than the Euclidean distance adopted by traditional approaches. In addition, we enforce and reformulate an orthogonal constraint as a novel layer stacked on an embedding network for two advantages, i.e. jointly optimizing the neural network and performing matrix decomposition and avoiding trivial solutions. Extensive experiments on four challenging datasets demonstrate the effectiveness of our method compared with 10 state-of-the-art approaches in terms of three evaluation metrics.},
}


@inproceedings{peng2019comic,
	Address = {Long Beach, California, USA},
	Author = {Peng, Xi and Huang, Zhenyu and Lv, Jiancheng and Zhu, Hongyuan and Zhou, Joey Tianyi},
	Booktitle = {Proceedings of the 36th International Conference on Machine Learning, {ICML-19}},
	Month = {09--15 Jun},
	Pages = {5092--5101},
	Publisher = {PMLR},
	Title = {{COMIC}: Multi-view Clustering Without Parameter Selection},
	Url = {http://proceedings.mlr.press/v97/peng19a.html},
	Volume = {97},
	Year = {2019},
	html = {http://proceedings.mlr.press/v97/peng19a.html},
	bib = {peng2019comic.bib},
	Pdfurl = {http://proceedings.mlr.press/v97/peng19a/peng19a.pdf},
	code = {https://github.com/limit-scu/2019-ICML-COMIC},
	abstract = {In this paper, we study two challenges in clustering analysis, namely, how to cluster multi-view data and how to perform clustering without parameter selection on cluster size. To this end, we propose a novel objective function to project raw data into one space in which the projection embraces the geometric consistency (GC) and the cluster assignment consistency (CAC). To be specific, the GC aims to learn a connection graph from a projection space wherein the data points are connected if and only if they belong to the same cluster. The CAC aims to minimize the discrepancy of pairwise connection graphs induced from different views based on the view-consensus assumption, \emph{i.e.}, different views could produce the same cluster assignment structure as they are different portraits of the same object. Thanks to the view-consensus derived from the connection graph, our method could achieve promising performance in learning view-specific representation and eliminating the heterogeneous gaps across different views. Furthermore, with the proposed objective, it could learn almost all parameters including the cluster number from data without labor-intensive parameter selection. Extensive experimental results show the promising performance achieved by our method on five datasets comparing with nine state-of-the-art multi-view clustering approaches.},
}


@article{huang2018mmfa,
  title={Multiple Marginal Fisher Analysis},
  author={Huang, Zhenyu and Zhu, Hongyuan and Zhou, Joey Tianyi and Peng, Xi},
  journal={IEEE Transactions on Industrial Electronics},
  year={2019},
  ISSN={0278-0046}, 
  month={Dec},
  volume={66}, 
  number={12}, 
  pages={9798-9807}, 
  publisher={IEEE},
  doi = {10.1109/TIE.2018.2870413},
  bib = {huang2018mmfa.bib},
  html = {https://ieeexplore.ieee.org/document/8476585},
  keywords={Dimensionality reduction;Learning systems;Manifolds;Task analysis;Robustness;Gaussian distribution;Estimation;Automatic dimension reduction;graph embedding;manifold learning;supervised subspace learning}, 
  abstract={Dimension reduction is a fundamental task of machine learning and computer vision, which is widely used in a variety of industrial applications. Over past decades, a lot of unsupervised and supervised algorithms have been proposed. However, few of them can automatically determine the feature dimension that could be adaptive to different data distributions. To obtain a good performance, it is popular to seek the optimal dimension by exhaustively enumerating some possible values. Clearly, such a scheme is ad-hoc and computational extensive. Therefore, a method which can automatically estimate the feature dimension in an efficient and principled manner is of significant practical and theoretical value. In this paper, we propose a novel supervised subspace learning method called multiple marginal fisher analysis (MMFA), which can automatically estimate the feature dimension. By maxing the  inter-class separability among marginal points while minimizing within-class scatter, MMFA obtains low-dimensional representations with outstanding discriminative properties. Extensive experiments show that MMFA not only outperforms other algorithms on clean data but also show robustness on corrupted and disguised data.},
}


